<a href="https://mlcourse.ai"><img src="img/ods/title.jpg"></a>

<table>
  <tbody>
    <!----------------------------------------------------- 1. EDA WITH PANDAS ----------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic1-teaser.jpg" /></td>
      <td>
        <h2>1. Exploratory data analysis with Pandas</h2>
        <ul>
          <li><a href="https://youtu.be/fwWCw_cE5aI">Video</a>: In the 1st lecture we get used to Pandas to perform preliminary data analysis.</li>
          <li><a href="https://mlcourse.ai/notebooks/blob/master/jupyter_english/topic01_pandas_data_analysis/topic1_pandas_data_analysis.ipynb?flush_cache=true">Notebook</a></li>
          <li><a href="https://www.kaggle.com/kashnitsky/a1-demo-pandas-and-uci-adult-dataset">Assignment</a>
          --><a href="https://www.kaggle.com/kashnitsky/a1-demo-pandas-and-uci-adult-dataset-solution">Solution</a></li>
        </ul>
      </td>
    </tr>
    <!---------------------------------------------------- 2. EDA VISUALIZATION ---------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic2-teaser.jpg" /></td>
      <td>
        <h2>2. Visualization, main plots for EDA</h2>
        <ul>
          <li><a href="https://youtu.be/WNoQTNOME5g">Video</a>: In the 2nd lecture, we discuss what typical plots are typically built when performing Exploratory Data Analysis.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic02_visual_data_analysis/topic2_visual_data_analysis.ipynb?flush_cache=true">Notebook 1</a>: From Simple Distributions to Dimensionality Reduction</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic02_visual_data_analysis/topic2_additional_seaborn_matplotlib_plotly.ipynb?flush_cache=true">Notebook 2</a>: Overview of Seaborn, Matplotlib and Plotly libraries</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a2-demo-analyzing-cardiovascular-data">Assignment</a>
           --><a href="https://www.kaggle.com/kashnitsky/a2-demo-analyzing-cardiovascular-data-solution">Solution</a> (Analyzing cardiovascular disease data)</li>
        </ul>
      </td>
    </tr>
    <!----------------------------------------------------- 3. DECISION TREES ----------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic3-teaser.png" /></td>
      <td>
        <h2>3. Decision trees and KNN</h2>
        <ul>
          <li><a href="https://youtu.be/H4XlBTPv5rQ">Video (theo)</a>: Here we start with basics of Machine Learning, then supervised learning, and cover classification decision trees in detail.</li>
          <li><a href="https://youtu.be/RrVYO6Td9Js">Video (prac)</a>: Here we use Sklearn to train, tune and visualize decision trees.</li>
          <li><a href="https://mlcourse.ai/notebooks/blob/master/jupyter_english/topic01_pandas_data_analysis/topic1_pandas_data_analysis.ipynb?flush_cache=true">Notebook</a></li>
          <li><a href="https://www.kaggle.com/kashnitsky/a3-demo-decision-trees">Assignment</a>
          --><a href="https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution">Solution</a></li>
        </ul>
      </td>
    </tr>
    <!--------------------------------------------------- 4. LINEAR CLASS & REGR --------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic4-teaser.png" /></td>
      <td>
        <h2>4. Linear Classification and Regression</h2>
        <ul>
          <li><a href="https://youtu.be/l3jiw-N544s">Video (theo)</a>: Mathematical foundations of  Logistic regression.</li>
          <li><a href="https://youtu.be/RrVYO6Td9Js">Video (prac)</a>: Alice competition with logistic regression.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic04_linear_models/topic4_linear_models_part1_mse_likelihood_bias_variance.ipynb?flush_cache=true">Notebook 1</a>: Ordinary Least Squares</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic04_linear_models/topic4_linear_models_part2_logit_likelihood_learning.ipynb?flush_cache=true">Notebook 2</a>: Logistic Regression</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic04_linear_models/topic4_linear_models_part3_regul_example.ipynb?flush-cache=true">Notebook 3</a>: Regularization</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic04_linear_models/topic4_linear_models_part4_good_bad_logit_movie_reviews_XOR.ipynb?flush_cache=true">Notebook 4</a>: Pros and Cons</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic04_linear_models/topic4_linear_models_part5_valid_learning_curves.ipynb?flush_cache=true">Notebook 5</a>: Validation and learning curves</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit">Assignment</a>
          --><a href="https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution">Solution</a> (Sarcasm detection)</li>
        </ul>
      </td>
    </tr>
    <!----------------------------------------------------- 5. RANDOM FOREST ----------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic5-teaser.png" /></td>
      <td>
        <h2>5. Ensembles of algorithms and random forest</h2>
        <ul>
          <li><a href="https://youtu.be/neXJL-AqI_c">Video (theo)</a>: Ensembles and Random Forest.</li>
          <li><a href="https://youtu.be/aBOMYqGUlWQ">Video (theo)</a>: Classification metrics.</li>
          <li><a href="https://youtu.be/FmKU-1LZGoE">Video (prac)</a>: Business task: predicting paying users.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true">Notebook 1</a>: Bagging</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true">Notebook 2</a>: Random Forest</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true">Notebook 3</a>: Feature importance</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring">Assignment</a>: Logistic Regression and Random Forest in the credit scoring problem</li>
        </ul>
      </td>
    </tr>
    <!--------------------------------------------------- 6. FEATURE ENGINEERING --------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic6-teaser.png" /></td>
      <td>
        <h2>6. Feature engineering and feature selection</h2>
        <ul>
          <li><a href="https://youtu.be/ne-MfRfYs_c">Video (theo)</a>: Linear regression and regularization.</li>
          <li><a href="https://youtu.be/B8yIaIEMyIc">Video (prac)</a>: LASSO & Ridge, LTV prediction.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic06_features_regression/topic6_feature_engineering_feature_selection.ipynb?flush_cache=true">Notebook</a>: Feature Engineering and Feature Selection.</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a6-demo-linear-models-and-rf-for-regression">Assignment</a>
          --><a href="https://www.kaggle.com/kashnitsky/a6-demo-linear-models-and-rf-for-regression-solution">Solution</a> Exploring OLS, Lasso and Random Forest in a regression task.</li>
        </ul>
      </td>
    </tr>
    <!-------------------------------------------------- 7. UNSUPERVISED LEARNING -------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic7-teaser.jpg" /></td>
      <td>
        <h2>7. Unsupervised learning</h2>
        <ul>
          <li><a href="https://youtu.be/-AswHf7h0I4">Video (theo & prac)</a>: Principal Component Analysis.</li>
          <li><a href="https://youtu.be/eVplCo-w4XE">Video (theo & prac)</a>: Clustering.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic07_unsupervised/topic7_pca_clustering.ipynb?flush_cache=true">Notebook</a>: PCA and clustering.</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a7-demo-unsupervised-learning">Assignment</a></li>
        </ul>
      </td>
    </tr>
    <!------------------------------------------------------ 8. VOWPAL WABBIT ------------------------------------------------------>
    <tr>
      <td><img width="300" src="img/ods/topic8-teaser.png" /></td>
      <td>
        <h2>8. Vowpal Wabbit: Learning with Gigabytes of Data</h2>
        <ul>
          <li><a href="https://youtu.be/EUSXbdzaQE8">Video</a>: Stochastic Gradient Descent for classification and regression.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic08_sgd_hashing_vowpal_wabbit/topic8_sgd_hashing_vowpal_wabbit.ipynb?flush_cache=true">Notebook</a>: Vowpal Wabbit: Learning with Gigabytes of Data</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a8-demo-implementing-online-regressor">Assignment</a>
          --><a href="https://www.kaggle.com/kashnitsky/a8-demo-implementing-online-regressor-solution">Solution</a>: Implementation of online regressor</li>
        </ul>
      </td>
    </tr>
    <!--------------------------------------------------- 9. TIME SERIES ANALYSIS --------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic9-teaser.jpg" /></td>
      <td>
        <h2>9. Time series analysis</h2>
        <ul>
          <li><a href="https://youtu.be/_9lBwXnbOd8">Video</a>: Time series analysis with Python (ARIMA, Prophet).</li>
          <li><a href="https://mlcourse.ai/notebooks/blob/master/jupyter_english/topic09_time_series/topic9_part1_time_series_python.ipynb?flush_cache=true">Notebook 1</a>: Part 1: Basics</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic09_time_series/topic9_part2_facebook_prophet.ipynb?flush_cache=true">Notebook 2</a>: Part 2: Predicting the future with Facebook Prophet</li>
          <li><a href="https://www.kaggle.com/kashnitsky/a9-demo-time-series-analysis">Assignment</a>
          --><a href="https://www.kaggle.com/kashnitsky/a9-demo-time-series-analysis-solution">Solution</a></li>
        </ul>
      </td>
    </tr>
    <!---------------------------------------------------- 10. GRADIENT BOOSTING ---------------------------------------------------->
    <tr>
      <td><img width="300" src="img/ods/topic10-teaser.jpg" /></td>
      <td>
        <h2>10. Gradient boosting</h2>
        <ul>
          <li><a href="https://youtu.be/g0ZOtzZqdqk">Video (theo)</a>: Gradient boosting basics.</li>
          <li><a href="https://youtu.be/V5158Oug4W8">Video (prac)</a>: Key ideas behind Xgboost, LightGBM, and CatBoost.</li>
          <li><a href="https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true">Notebook</a></li>
          <li><a href="https://www.kaggle.com/kashnitsky/assignment-10-gradient-boosting-and-flight-delays">Assignment</a>: Beating baseline in a competition</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
